[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a researcher and data scientist with a strong background in cognitive science, statistics, and machine learning. My research endeavor spans computational vision, Bayesian modeling, and decision-making, with applications in health research and neuroscience. I have experience implementing machine learning models for medical imaging analysis, predictive modeling, and data-driven insights in psychology and healthcare. My recent projects include using deep learning to study visual memory in the brain and applying statistical models to predict health outcomes such as obesity and heart disease. I am passionate about leveraging data to uncover meaningful patterns, enhance human understanding, and drive innovation in cognitive science and artificial intelligence."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Yiting",
    "section": "",
    "text": "Welcome! See what projects I have worked on!\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPredicting Obesity Status Using Machine Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeart Disease Prediction with Naive Bayes Classifier\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/01_project.html",
    "href": "projects/01_project.html",
    "title": "Predicting Obesity Status Using Machine Learning",
    "section": "",
    "text": "This project explores the prediction of obesity status using statistical and machine learning techniques. Leveraging a dataset from Kaggle, the study applies logistic regression and random forest models to classify individuals as “Obese” or “Not Obese.” The study emphasizes the importance of multicollinearity checks, model selection, and data preprocessing to improve predictive accuracy. Results show that while logistic regression provides interpretability, the random forest model achieves superior accuracy by capturing complex relationships. Future improvements include incorporating additional demographic features and testing more machine learning models such as Support Vector Machines (SVM) and Gradient Boosting Machines (GBM)."
  },
  {
    "objectID": "projects/01_project.html#summary",
    "href": "projects/01_project.html#summary",
    "title": "Predicting Obesity Status Using Machine Learning",
    "section": "",
    "text": "This project explores the prediction of obesity status using statistical and machine learning techniques. Leveraging a dataset from Kaggle, the study applies logistic regression and random forest models to classify individuals as “Obese” or “Not Obese.” The study emphasizes the importance of multicollinearity checks, model selection, and data preprocessing to improve predictive accuracy. Results show that while logistic regression provides interpretability, the random forest model achieves superior accuracy by capturing complex relationships. Future improvements include incorporating additional demographic features and testing more machine learning models such as Support Vector Machines (SVM) and Gradient Boosting Machines (GBM)."
  },
  {
    "objectID": "projects/01_project.html#highlights",
    "href": "projects/01_project.html#highlights",
    "title": "Predicting Obesity Status Using Machine Learning",
    "section": "Highlights",
    "text": "Highlights\n\nImplemented logistic regression and random forest models for obesity classification.\n\nConducted multicollinearity analysis using the Variance Inflation Factor (VIF).\n\nThe random forest model achieved nearly 100% training accuracy, outperforming logistic regression.\n\nIdentified significant predictors such as physical activity frequency, dietary habits, and genetic predisposition.\n\nProposed future improvements including feature expansion and advanced classification techniques.\n\nDOWNLOAD: download report here"
  },
  {
    "objectID": "projects/02_project.html",
    "href": "projects/02_project.html",
    "title": "Heart Disease Prediction with Naive Bayes Classifier",
    "section": "",
    "text": "This project investigates the use of the Naive Bayes classifier for predicting heart disease based on a dataset from Kaggle. The study evaluates multiple variations of Naive Bayes, including Gaussian, Bernoulli, and Categorical models, to determine the most effective approach. Results indicate that the categorical model performs best, achieving an accuracy of 85.7%. The analysis also examines the independence assumption of Naive Bayes, showing limitations in handling correlated predictors. While the model provides high interpretability, future work will focus on improving recall and testing more advanced classification methods such as Decision Trees and Random Forests."
  },
  {
    "objectID": "projects/02_project.html#summary",
    "href": "projects/02_project.html#summary",
    "title": "Heart Disease Prediction with Naive Bayes Classifier",
    "section": "",
    "text": "This project investigates the use of the Naive Bayes classifier for predicting heart disease based on a dataset from Kaggle. The study evaluates multiple variations of Naive Bayes, including Gaussian, Bernoulli, and Categorical models, to determine the most effective approach. Results indicate that the categorical model performs best, achieving an accuracy of 85.7%. The analysis also examines the independence assumption of Naive Bayes, showing limitations in handling correlated predictors. While the model provides high interpretability, future work will focus on improving recall and testing more advanced classification methods such as Decision Trees and Random Forests."
  },
  {
    "objectID": "projects/02_project.html#highlights",
    "href": "projects/02_project.html#highlights",
    "title": "Heart Disease Prediction with Naive Bayes Classifier",
    "section": "Highlights",
    "text": "Highlights\n\nUtilized Naive Bayes classifiers (Gaussian, Bernoulli, and Categorical) for heart disease prediction.\n\nAnalyzed feature distributions and data covariance to assess the model’s assumptions.\n\nThe categorical Naive Bayes model achieved the highest accuracy at 85.7%.\n\nExplored model aggregation to enhance predictive performance.\n\nProposed future improvements, including larger datasets, additional predictors, and alternative machine learning methods.\n\nDOWNLOAD: download report here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yiting Wang",
    "section": "",
    "text": "Yiting is a senior undergrad at UCLA majoring in Statistics B.S. and Cognitive Science B.S.. She is also a 25Fall incoming Ph.D student for UIUC Psychology. She is excited to learn about spatial learning and memories. In her spare time, Yiting reads, cooks, takes walks and listen to music.\nThe LinkedIn tab might not function properly due to recent changes to the link address of my personal profile. If that happens please come back and try again later. Thanks!"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Yiting Wang",
    "section": "Education",
    "text": "Education\nUniversity of California, Los Angeles | Los Angeles, CA.\nBachelors in Statistics and Cognitive Science | Sept 2023- August 2025."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Yiting Wang",
    "section": "Experience",
    "text": "Experience\nLeading Editor | Undergrad Journal of Psychology at UCLA\nSept 2023- Now\nLed weekly discussions among editors to review submissions of psychology papers from undergraduate students"
  },
  {
    "objectID": "index.html#cv",
    "href": "index.html#cv",
    "title": "Yiting Wang",
    "section": "CV",
    "text": "CV\nLearn more about me from my CV"
  }
]